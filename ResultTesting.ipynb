{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "38ae046b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFrom\\nhttps://www.tensorflow.org/tutorials/audio/simple_audio\\nA simple script that predicts results\\n'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "From\n",
    "https://www.tensorflow.org/tutorials/audio/simple_audio\n",
    "A simple script that predicts results\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ea23feac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from IPython import display\n",
    "\n",
    "# Set the seed value for experiment reproducibility.\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ea86fc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "class_names = [x for x in string.ascii_lowercase]\n",
    "class_names = class_names + [str(x) for x in range(0, 10, 1)]\n",
    "class_names.append(\"noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4b427938",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path(\"./training_data\")\n",
    "\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*/*')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "num_samples = len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e8e32cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = filenames[:int(500 * 0.8)]\n",
    "val_files = filenames[int(500 * 0.8): int(500 * 0.9)]\n",
    "test_files = filenames[int(500 * 0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9073b674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_audio(audio_binary):\n",
    "    # Decode WAV-encoded audio files to `float32` tensors, normalized\n",
    "    # to the [-1.0, 1.0] range. Return `float32` audio and a sample rate.\n",
    "    audio, _ = tf.audio.decode_wav(contents=audio_binary)\n",
    "    # Since all the data is single channel (mono), drop the `channels`\n",
    "    # axis from the array.\n",
    "    return tf.squeeze(audio, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ecbfb1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(\n",
    "        input=file_path,\n",
    "        sep=os.path.sep)\n",
    "    # Note: You'll use indexing here instead of tuple unpacking to enable this\n",
    "    # to work in a TensorFlow graph.\n",
    "    return parts[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "369a5cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_waveform_and_label(file_path):\n",
    "    label = get_label(file_path)\n",
    "    audio_binary = tf.io.read_file(file_path)\n",
    "    waveform = decode_audio(audio_binary)\n",
    "    return waveform, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b50676a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(train_files)\n",
    "\n",
    "waveform_ds = files_ds.map(\n",
    "    map_func=get_waveform_and_label,\n",
    "    num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0df6f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram(waveform):\n",
    "    # Zero-padding for an audio waveform with less than 16,000 samples.\n",
    "    input_len = 16000\n",
    "    waveform = waveform[:input_len]\n",
    "    zero_padding = tf.zeros(\n",
    "      [16000] - tf.shape(waveform),\n",
    "      dtype=tf.float32)\n",
    "    # Cast the waveform tensors' dtype to float32.\n",
    "    waveform = tf.cast(waveform, dtype=tf.float32)\n",
    "    # Concatenate the waveform with `zero_padding`, which ensures all audio\n",
    "    # clips are of the same length.\n",
    "    equal_length = tf.concat([waveform, zero_padding], 0)\n",
    "    # Convert the waveform to a spectrogram via a STFT.\n",
    "    spectrogram = tf.signal.stft(\n",
    "      equal_length, frame_length=255, frame_step=128)\n",
    "    # Obtain the magnitude of the STFT.\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    # Add a `channels` dimension, so that the spectrogram can be used\n",
    "    # as image-like input data with convolution layers (which expect\n",
    "    # shape (`batch_size`, `height`, `width`, `channels`).\n",
    "    spectrogram = spectrogram[..., tf.newaxis]\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2783dcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for waveform, label in waveform_ds.take(1):\n",
    "    label = label.numpy().decode('utf-8')\n",
    "    spectrogram = get_spectrogram(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "57a44272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(spectrogram, ax):\n",
    "    if len(spectrogram.shape) > 2:\n",
    "        assert len(spectrogram.shape) == 3\n",
    "        spectrogram = np.squeeze(spectrogram, axis=-1)\n",
    "    # Convert the frequencies to log scale and transpose, so that the time is\n",
    "    # represented on the x-axis (columns).\n",
    "    # Add an epsilon to avoid taking a log of zero.\n",
    "    log_spec = np.log(spectrogram.T + np.finfo(float).eps)\n",
    "    height = log_spec.shape[0]\n",
    "    width = log_spec.shape[1]\n",
    "    X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n",
    "    Y = range(height)\n",
    "    ax.pcolormesh(X, Y, log_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a687f50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram_and_label_id(audio, label):\n",
    "    spectrogram = get_spectrogram(audio)\n",
    "    label_id = tf.math.argmax(label == class_names)\n",
    "    return spectrogram, label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "80a1446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram_ds = waveform_ds.map(\n",
    "  map_func=get_spectrogram_and_label_id,\n",
    "  num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d5431ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(files):\n",
    "    files_ds = tf.data.Dataset.from_tensor_slices(files)\n",
    "    output_ds = files_ds.map(\n",
    "        map_func=get_waveform_and_label,\n",
    "        num_parallel_calls=AUTOTUNE)\n",
    "    output_ds = output_ds.map(\n",
    "        map_func=get_spectrogram_and_label_id,\n",
    "        num_parallel_calls=AUTOTUNE)\n",
    "    return output_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d6294f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "model = keras.models.load_model('./saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d21802bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sound(file_name, graphing=False):\n",
    "    \"\"\"\n",
    "    A function that does classification on file_name\n",
    "    :param file_name: the string that represents file_name\n",
    "    :param graphing: if set True, it will show graph visualization on results\n",
    "    \"\"\"\n",
    "    sample_file = file_name\n",
    "    sample_ds = preprocess_dataset([str(sample_file)])\n",
    "    for spectrogram, label in sample_ds.batch(1):\n",
    "        prediction = model(spectrogram)\n",
    "        result = tf.nn.softmax(prediction[0]).numpy()\n",
    "        list_result = result.tolist()\n",
    "        max_val = max(result)\n",
    "        max_val_index = list_result.index(max_val)\n",
    "\n",
    "        class_label = class_names[max_val_index]\n",
    "\n",
    "        if graphing:\n",
    "            plt.bar(class_names, tf.nn.softmax(prediction[0]))\n",
    "            plt.title(f'Predictions for \"{class_label}\"')\n",
    "            plt.show()\n",
    "            \n",
    "    return class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17bdae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def solve_captcha_letters(file_name):\n",
    "    \"\"\"\n",
    "    A function that does predict_sound over all .wav files in directory ./separated.\n",
    "    After this is done processing, it will delete all .wav files.\n",
    "    :return: list object that represents all captcha letters.\n",
    "    \"\"\"\n",
    "    cur_path = os.getcwd()\n",
    "    splitted_path = os.path.join(cur_path, file_name + \"_splitted\")\n",
    "    results = list()\n",
    "    file_count = 0\n",
    "\n",
    "    for file in os.listdir(splitted_path):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith(\".wav\"): \n",
    "            file_count += 1\n",
    "            continue\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    for i in range(file_count):\n",
    "        file_path = os.path.join(splitted_path, str(i) + \".wav\")\n",
    "        prediction = predict_sound(file_path)\n",
    "        if prediction != \"noise\":\n",
    "            results.append(prediction)\n",
    "        os.remove(file_path)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bc681d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
